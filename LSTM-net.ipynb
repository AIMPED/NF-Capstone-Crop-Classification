{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96b724e",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "All the dependencies for this notebook are included in the `requirements.txt` file included in this folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a173ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52c8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "\n",
    "import tile_utils as tilu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3195a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_to_number = {\"B01\":0, \"B02\":1, \"B03\":2, \"B04\":3, \"B05\":4, \"B06\":5, \"B07\":6, \"B08\":7,\n",
    "                     \"B09\":8, \"B11\":9, \"B12\":10, \"B8A\":11, \"CLM\":None, \"BS_IDX\": 12, \"MOIST_IDX\": 13, \"NDVI_IDX\": 14}\n",
    "number_to_channel = {number: channel for channel, number in channel_to_number.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0223994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ndviindex(image, channel_to_number):\n",
    "    image_B08 = image[channel_to_number['B08'],:,:]\n",
    "    image_B04 = image[channel_to_number['B04'],:,:]\n",
    "    non_zero = (image_B08 + image_B04 != 0)\n",
    "    ndvi_index = np.zeros((image.shape[1], image.shape[2]))\n",
    "    ndvi_index[non_zero] = np.nan_to_num((image_B08[non_zero] - image_B04[non_zero]) / (image_B08[non_zero] + image_B04[non_zero]))\n",
    "    \n",
    "    upper_limit = 1\n",
    "    lower_limit = -0.2\n",
    "    \n",
    "    ndvi_index = np.where(ndvi_index > lower_limit, ndvi_index , lower_limit)\n",
    "    ndvi_index = np.where(ndvi_index < upper_limit, ndvi_index , upper_limit)\n",
    "    \n",
    "    return ndvi_index\n",
    "\n",
    "def create_moistureindex(image, channel_to_number):\n",
    "    image_B8A = image[channel_to_number['B8A'],:,:]\n",
    "    image_B11 = image[channel_to_number['B11'],:,:]\n",
    "    non_zero = (image_B8A + image_B11 != 0)\n",
    "    moisture_index = np.zeros((image.shape[1], image.shape[2]))\n",
    "    moisture_index[non_zero] = np.nan_to_num((image_B8A[non_zero] - image_B11[non_zero]) / (image_B8A[non_zero] + image_B11[non_zero]))\n",
    "    \n",
    "    upper_limit = 2\n",
    "    lower_limit = -0.8\n",
    "    \n",
    "    moisture_index = np.where(moisture_index > lower_limit, moisture_index , lower_limit)\n",
    "    moisture_index = np.where(moisture_index < upper_limit, moisture_index , upper_limit)\n",
    "    \n",
    "    return moisture_index\n",
    "\n",
    "def create_baresoilindex(image, channel_to_number):\n",
    "    \n",
    "    # Other option found: NBSI = ((B11 + B04)-(B08 + B02))/((B11 + B04)+(B08 + B02))\n",
    "    \n",
    "    image_B11 = image[channel_to_number['B11'],:,:]\n",
    "    image_B08 = image[channel_to_number['B08'],:,:]\n",
    "    image_B04 = image[channel_to_number['B04'],:,:]\n",
    "    image_B02 = image[channel_to_number['B02'],:,:]\n",
    "    \n",
    "    non_zero = (image_B11 + image_B02 + image_B04 + image_B08 != 0)\n",
    "    baresoil_index = np.zeros((image.shape[1], image.shape[2]))\n",
    "    baresoil_index[non_zero] = np.nan_to_num(((image_B11[non_zero] + image_B04[non_zero]) - (image_B02[non_zero] + image_B08[non_zero])) / (image_B11[non_zero] + image_B02[non_zero] + image_B04[non_zero] + image_B08[non_zero]))\n",
    "    \n",
    "    return baresoil_index\n",
    "\n",
    "def read_tile_geojson(path):\n",
    "    tiles = gpd.read_file(path)\n",
    "    for column in tiles.select_dtypes(include='object').columns:\n",
    "        try:\n",
    "            tiles[column] = tiles[column].apply(eval)\n",
    "        except:\n",
    "            pass\n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac8912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def tile_dataset(orig_path, extra_data, tiles_info, train=True, radius=16):\n",
    "    if train==True:\n",
    "        path_app = ''\n",
    "    else:\n",
    "        path_app = '_test'\n",
    "    \n",
    "    tile_id = int(str(orig_path).split(\"/\")[-1].split(\"'\")[0])\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(tile_id)\n",
    "    \n",
    "    list_tile = os.listdir(f'/home/jupyter/NF-Capstone-Crop-Classification/stacked_files_CNN{path_app}/{tile_id}/s2/')\n",
    "    field_ids = rasterio.open(f'/home/jupyter/NF-Capstone-Crop-Classification/stacked_files_CNN{path_app}/{tile_id}/field_ids.tif').read(1)\n",
    "    \n",
    "    if train == True:\n",
    "        labels = rasterio.open(f'/home/jupyter/NF-Capstone-Crop-Classification/stacked_files_CNN{path_app}/{tile_id}/labels.tif').read(1)\n",
    "    \n",
    "    days_tile = []\n",
    "    \n",
    "    for f in list_tile:\n",
    "        days_tile.append(int(str(f).split(\"/\")[-1].split(\"_\")[-2]))\n",
    "    days_tile = sorted(days_tile)\n",
    "    \n",
    "    field_ids_tile = list(np.unique(field_ids))\n",
    "    field_ids_tile.remove(0)\n",
    "\n",
    "    \n",
    "    imgs = np.zeros((len(field_ids_tile),len(days_tile),15,radius*2,radius*2), dtype = np.float32)\n",
    "    field_masks = np.zeros((len(field_ids_tile), 1, 1, radius*2, radius*2), dtype = np.float32)\n",
    "    extra = np.zeros((len(field_ids_tile), 13))\n",
    "    \n",
    "    if train == True:\n",
    "        field_labels = np.zeros((len(field_ids_tile),10))\n",
    "    \n",
    "    # load images for all days of this tile into dictionary\n",
    "    img = dict()\n",
    "    for num_day, day in enumerate(days_tile):\n",
    "        img_path = f'/home/jupyter/NF-Capstone-Crop-Classification/stacked_files_CNN{path_app}/{tile_id}/s2/{tile_id}_s2_{day}_stacked.tif'         \n",
    "        img[num_day] = rasterio.open(img_path).read() \n",
    "        \n",
    "    num_neigh = len(eval(tiles_info.query('tile_id == 500').tiles_closest.iloc[0]))\n",
    "\n",
    "    ifx = 0                   \n",
    "    for field_id in field_ids_tile:\n",
    "        \n",
    "        field_mask = (field_ids==field_id)\n",
    "        if train == True:\n",
    "            field_labels[ifx,round(np.mean(labels[field_mask]))] = 1\n",
    "            \n",
    "        idxx = np.where(field_mask)\n",
    "        momentx = np.median(idxx[0]).astype(np.int)\n",
    "        momenty = np.median(idxx[1]).astype(np.int)\n",
    "\n",
    "        field_patch = field_mask[max(0, momentx-radius): momentx+radius, max(0, momenty-radius): momenty+radius]\n",
    "\n",
    "        \n",
    "        if field_patch.sum() == 0:\n",
    "            momentx = np.min(idxx[0]).astype(np.int)\n",
    "            momenty = np.min(idxx[1]).astype(np.int)  \n",
    "            field_patch = field_mask[max(0, momentx-radius): momentx+radius, max(0, momenty-radius): momenty+radius]\n",
    "            \n",
    "        if field_patch.sum() == 0:\n",
    "            print('PATCH ZERO')\n",
    "            print(ifx, momentx-radius, momentx+radius, momenty-radius, momenty+radius)\n",
    "        \n",
    "\n",
    "        for num_day, day in enumerate(days_tile):\n",
    "            patch = img[num_day][0:12,max(0, momentx-radius): momentx+radius, max(0, momenty-radius): momenty+radius]\n",
    "\n",
    "            imgs[ifx, num_day, 0:12, :patch.shape[-2], :patch.shape[-1]] = patch\n",
    "            imgs[ifx, num_day, channel_to_number['MOIST_IDX'], :patch.shape[-2], :patch.shape[-1]] = create_moistureindex(patch, channel_to_number)\n",
    "            imgs[ifx, num_day, channel_to_number['BS_IDX'], :patch.shape[-2], :patch.shape[-1]] = create_baresoilindex(patch, channel_to_number)\n",
    "            imgs[ifx, num_day, channel_to_number['NDVI_IDX'], :patch.shape[-2], :patch.shape[-1]] = create_ndviindex(patch, channel_to_number)\n",
    "        \n",
    "\n",
    "        #pad crop's field mask in tiles borders with zeros\n",
    "        field_masks[ifx, :, :, :patch.shape[-2], :patch.shape[-1]] = field_patch            \n",
    "        extra[ifx, :12]  = np.array(extra_data.query('field_id == @field_id').drop('field_id', axis=1).values.tolist()[0])         \n",
    "        extra[ifx, 12] = num_neigh\n",
    "            \n",
    "        ifx += 1\n",
    "        \n",
    "    if train == True:        \n",
    "        return tf.data.Dataset.from_tensor_slices((imgs, field_masks, extra, field_labels))\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices((imgs, field_masks, extra)), field_ids_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971fe62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_dataset = tf.data.Dataset.list_files(f'/home/jupyter/NF-Capstone-Crop-Classification/stacked_files_CNN/*', shuffle=False)\n",
    "\n",
    "fields_train_mean_var = pd.read_csv('data/mean_var_8days_train.csv')[['field_id', 'elevation', 'field_area_km2', 'sun_rate','neighboor_label_1', 'neighboor_label_2','neighboor_label_3',\n",
    "                                'neighboor_label_4','neighboor_label_5', 'neighboor_label_6','neighboor_label_7', 'neighboor_label_8', 'neighboor_label_9']]\n",
    "\n",
    "tiles_train = tilu.read_tile_geojson('data/tiles_train.geojson')\n",
    "tiles_train_crs32634 = tiles_train.to_crs(32634)\n",
    "\n",
    "# apply with a threshold of 4000m\n",
    "tiles_train['tiles_closest'] = tiles_train_crs32634.apply(tilu.tiles_closest, axis='columns', args=(tiles_train_crs32634, 4000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ad3402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "for i, f in enumerate(tiles_dataset.as_numpy_iterator()):\n",
    "    if i == 0:\n",
    "        train_ds = tile_dataset(f, train=True, radius=16, extra_data=fields_train_mean_var, tiles_info=tiles_train)\n",
    "    elif i<2000:\n",
    "        train_ds = train_ds.concatenate(tile_dataset(f, train=True, radius=16, extra_data=fields_train_mean_var, tiles_info=tiles_train))\n",
    "    elif i == 2000:\n",
    "        val_ds = tile_dataset(f, train=True, radius=16, extra_data=fields_train_mean_var, tiles_info=tiles_train)\n",
    "    elif i<3000:\n",
    "        val_ds = val_ds.concatenate(tile_dataset(f, train=True, radius=16, extra_data=fields_train_mean_var, tiles_info=tiles_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "12c5e724",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "51\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "52\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "53\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "54\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "55\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "56\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "57\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "58\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "59\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "6\n",
      "60\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "61\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "62\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "63\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "64\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "65\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "66\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "67\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "68\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "69\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "7\n",
      "70\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "71\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "72\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "73\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-296-404b2c8cb39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtile_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields_train_mean_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m2100\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields_train_mean_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-295-f22de413f780>\u001b[0m in \u001b[0;36mtile_dataset\u001b[0;34m(orig_path, extra_data, train, radius)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum_day\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays_tile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/home/jupyter/NF-Capstone-Crop-Classification/stacked_files_CNN{path_app}/{tile_id}/s2/{tile_id}_s2_{day}_stacked.tif'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_day\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, f in enumerate(tiles_dataset.as_numpy_iterator()):\n",
    "    if i == 2100:\n",
    "        val_ds = tile_dataset(f, train=True, radius=16, extra_data=fields_train_mean_var)\n",
    "    elif 2100 < i< 3000:\n",
    "        val_ds = val_ds.concatenate(tile_dataset(f, train=True, radius=16, extra_data=fields_train_mean_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62ebf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51a7093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "class DropMaskModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x = data[0]\n",
    "        mask = data[1]\n",
    "        extra = data[2]\n",
    "        y = data[3]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self((x, mask, extra), training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x = data[0]\n",
    "        mask = data[1]\n",
    "        extra = data[2]\n",
    "        y = data[3]\n",
    "        \n",
    "        # Compute predictions\n",
    "        y_pred = self((x, mask, extra), training=False)\n",
    "        # Updates the metrics tracking the loss\n",
    "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def predict_step(self, data):\n",
    "        \"\"\"The logic for one inference step.\n",
    "        This method can be overridden to support custom inference logic.\n",
    "        This method is called by `Model.make_predict_function`.\n",
    "        This method should contain the mathematical logic for one step of inference.\n",
    "        This typically includes the forward pass.\n",
    "        Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
    "        `tf.distribute.Strategy` settings), should be left to\n",
    "        `Model.make_predict_function`, which can also be overridden.\n",
    "        Args:\n",
    "          data: A nested structure of `Tensor`s.\n",
    "        Returns:\n",
    "          The result of one inference step, typically the output of calling the\n",
    "          `Model` on data.\n",
    "        \"\"\"\n",
    "        x = data[0]\n",
    "        mask = data[1]\n",
    "        extra = data[2]\n",
    "\n",
    "        return self((x, mask, extra), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "442b285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_lstm2222_numneigh/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8f45769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f64897cb5d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65231b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a2653c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete_ds = train_ds.concatenate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf1c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "86/86 [==============================] - 625s 7s/step - loss: 0.9889 - accuracy: 0.6616 - val_loss: 1.1056 - val_accuracy: 0.6098\n",
      "\n",
      "Epoch 00001: saving model to training_lstm2222_numneigh/cp.ckpt\n",
      "Epoch 2/5\n",
      "86/86 [==============================] - 625s 7s/step - loss: 0.9710 - accuracy: 0.6697 - val_loss: 1.1121 - val_accuracy: 0.5961\n",
      "\n",
      "Epoch 00002: saving model to training_lstm2222_numneigh/cp.ckpt\n",
      "Epoch 3/5\n",
      "86/86 [==============================] - 625s 7s/step - loss: 0.9568 - accuracy: 0.6729 - val_loss: 1.0300 - val_accuracy: 0.6279\n",
      "\n",
      "Epoch 00003: saving model to training_lstm2222_numneigh/cp.ckpt\n",
      "Epoch 4/5\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9389 - accuracy: 0.6783"
     ]
    }
   ],
   "source": [
    "training = cnn.fit(train_complete_ds, validation_data=val_ds, epochs = 5, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c62962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"drop_mask_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer (InputLayer)        [(None, 8, 15, 32, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 8, 15, 32, 32 31          Input_Layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 8, 32, 32, 32 4352        normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 8, 32, 32, 32 0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 8, 32, 32, 32 1024        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 8, 64, 32, 32 18496       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 64, 32, 32 0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 64, 32, 32 2048        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1, 32, 32 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 8, 64, 32, 32 0           batch_normalization_1[0][0]      \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 8, 64)        0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 1, 1)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (None, 8, 64)        0           tf.math.reduce_sum[0][0]         \n",
      "                                                                 tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 13)           27          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           33024       tf.math.truediv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 13)           52          normalization_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 77)           0           lstm[0][0]                       \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          19968       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           330         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 188,376\n",
      "Trainable params: 186,756\n",
      "Non-trainable params: 1,620\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_lstm(days, width, height, depth):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (days, depth, height, width)\n",
    "    chanDim = [1, 2]\n",
    "    \n",
    "    # define the model input    \n",
    "    img = tf.keras.Input(shape=inputShape, name='Input_Layer')\n",
    "    mask = tf.keras.Input(shape=(1,1,32,32))\n",
    "    extra = tf.keras.Input(shape=(13))\n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.experimental.preprocessing.Normalization(axis=2)(img)\n",
    "    \n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(32, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "\n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "\n",
    "    x = x * mask    \n",
    "    x = tf.math.reduce_sum(x, axis = [3,4])\n",
    "    mask_sum = tf.math.reduce_sum(mask, axis = [3,4])\n",
    "    x = (x / mask_sum)\n",
    "    \n",
    "    x = tf.keras.layers.LSTM(64)(x)\n",
    "    \n",
    "    y = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)(extra)\n",
    "    y = BatchNormalization()(y)\n",
    "    \n",
    "    x = tf.keras.layers.concatenate([x, y])\n",
    "    \n",
    "    x = Dense(256, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(256, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(128, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(64, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(32, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(10, kernel_initializer = 'HeUniform')(x)\n",
    "    \n",
    "    \n",
    "    # construct the CNN\n",
    "    model = DropMaskModel(inputs=[img, mask, extra], outputs=x)\n",
    "    # return the CNN\n",
    "\n",
    "    return model\n",
    "\n",
    "cnn = create_cnn_lstm(8, 32, 32, 15)\n",
    "#cnn.compile(optimizer = 'adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a79da67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"drop_mask_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer (InputLayer)        [(None, 8, 15, 32, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 8, 15, 32, 32 31          Input_Layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 8, 32, 32, 32 4352        normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 8, 32, 32, 32 0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 8, 32, 32, 32 1024        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 8, 64, 32, 32 18496       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 64, 32, 32 0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 64, 32, 32 2048        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1, 32, 32 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 8, 64, 32, 32 0           batch_normalization_1[0][0]      \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 8, 64)        0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 1, 1)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (None, 8, 64)        0           tf.math.reduce_sum[0][0]         \n",
      "                                                                 tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 13)           27          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           tf.math.truediv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 13)           52          normalization_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 525)          0           flatten[0][0]                    \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          134656      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           330         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 270,040\n",
      "Trainable params: 268,420\n",
      "Non-trainable params: 1,620\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_temp_woGRU_RELU(days, width, height, depth):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (days, depth, height, width)\n",
    "    chanDim = [1, 2]\n",
    "    \n",
    "    # define the model input    \n",
    "    img = tf.keras.Input(shape=inputShape, name='Input_Layer')\n",
    "    mask = tf.keras.Input(shape=(1,1,32,32))\n",
    "    extra = tf.keras.Input(shape=(13))\n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.experimental.preprocessing.Normalization(axis=2)(img)\n",
    "    \n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(32, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "\n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "\n",
    "    x = x * mask    \n",
    "    x = tf.math.reduce_sum(x, axis = [3,4])\n",
    "    mask_sum = tf.math.reduce_sum(mask, axis = [3,4])\n",
    "    x = (x / mask_sum)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    y = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)(extra)\n",
    "    y = BatchNormalization()(y)\n",
    "    \n",
    "    x = tf.keras.layers.concatenate([x, y])\n",
    "    \n",
    "    x = Dense(256, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(256, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(128, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(64, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(32, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(10, kernel_initializer = 'HeUniform')(x)\n",
    "    \n",
    "    \n",
    "    # construct the CNN\n",
    "    model = DropMaskModel(inputs=[img, mask, extra], outputs=x)\n",
    "    # return the CNN\n",
    "\n",
    "    return model\n",
    "\n",
    "cnn = create_cnn_temp_woGRU_RELU(8, 32, 32, 15)\n",
    "#cnn.compile(optimizer = 'adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16dd39f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"drop_mask_model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer (InputLayer)        [(None, 8, 15, 32, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 8, 16, 32, 32 2176        Input_Layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 16, 32, 32 512         time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 8, 32, 32, 32 4640        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 32, 32, 32 1024        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 8, 64, 32, 32 18496       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 64, 32, 32 2048        time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1, 1, 32, 32 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 8, 64, 32, 32 0           batch_normalization_10[0][0]     \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_4 (TFOpLambd (None, 8, 64)        0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_5 (TFOpLambd (None, 1, 1)         0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_2 (TFOpLambda)  (None, 8, 64)        0           tf.math.reduce_sum_4[0][0]       \n",
      "                                                                 tf.math.reduce_sum_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 512)          0           tf.math.truediv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 12)           48          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 524)          0           flatten_2[0][0]                  \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          134400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          65792       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 256)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256)          0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           16448       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64)           0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           2080        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32)           0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 10)           330         dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 247,994\n",
      "Trainable params: 246,178\n",
      "Non-trainable params: 1,816\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_temp_woGRU(days, width, height, depth):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (days, depth, height, width)\n",
    "    chanDim = [1, 2]\n",
    "    \n",
    "    # define the model input    \n",
    "    img = tf.keras.Input(shape=inputShape, name='Input_Layer')\n",
    "    mask = tf.keras.Input(shape=(1,1,32,32))\n",
    "    extra = tf.keras.Input(shape=(12))\n",
    "    \n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(16, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(img)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    \n",
    "    #max_pool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), data_format='channels_first')\n",
    "    #x = tf.keras.layers.TimeDistributed(max_pool_layer)(x)\n",
    "    \n",
    "    \n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(32, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    #max_pool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), data_format='channels_first')\n",
    "    #x = tf.keras.layers.TimeDistributed(max_pool_layer)(x)\n",
    "    \n",
    "    \n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "\n",
    "    x = x * mask    \n",
    "    x = tf.math.reduce_sum(x, axis = [3,4])\n",
    "    mask_sum = tf.math.reduce_sum(mask, axis = [3,4])\n",
    "    x = (x / mask_sum)\n",
    "    \n",
    "    #gru = tf.keras.layers.GRU(64, return_sequences=False, return_state=False)\n",
    "    #x = gru(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    y = BatchNormalization()(extra)\n",
    "    x = tf.keras.layers.concatenate([x, y])\n",
    "    \n",
    "    x = Dense(256, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(256, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(64, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(32, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(10, kernel_initializer = 'HeUniform')(x)\n",
    "    \n",
    "    \n",
    "    # construct the CNN\n",
    "    model = DropMaskModel(inputs=[img, mask, extra], outputs=x)\n",
    "    # return the CNN\n",
    "\n",
    "    return model\n",
    "\n",
    "cnn = create_cnn_temp_woGRU(8, 32, 32, 15)\n",
    "#cnn.compile(optimizer = 'adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60835b41",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"drop_mask_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer (InputLayer)        [(None, 8, 15, 32, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 8, 15, 32, 32 31          Input_Layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 8, 32, 32, 32 4352        normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 8, 32, 32, 32 0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 8, 32, 32, 32 1024        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 8, 64, 32, 32 18496       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 64, 32, 32 0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 8, 64, 32, 32 2048        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1, 1, 32, 32 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 8, 64, 32, 32 0           batch_normalization_1[0][0]      \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 8, 64)        0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 1, 1)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (None, 8, 64)        0           tf.math.reduce_sum[0][0]         \n",
      "                                                                 tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 64)           24960       tf.math.truediv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 12)           25          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 76)           0           gru[0][0]                        \n",
      "                                                                 normalization_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          9856        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           330         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 87,970\n",
      "Trainable params: 86,378\n",
      "Non-trainable params: 1,592\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_GRU_norm(days, width, height, depth):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (days, depth, height, width)\n",
    "    chanDim = [1, 2]\n",
    "    \n",
    "    # define the model input    \n",
    "    img = tf.keras.Input(shape=inputShape, name='Input_Layer')\n",
    "    mask = tf.keras.Input(shape=(1,1,32,32))\n",
    "    extra = tf.keras.Input(shape=(12))\n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.experimental.preprocessing.Normalization(axis=2)(img)\n",
    "    \n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(32, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    #max_pool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), data_format='channels_first')\n",
    "    #x = tf.keras.layers.TimeDistributed(max_pool_layer)(x)\n",
    "    \n",
    "    \n",
    "    conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3), data_format='channels_first', padding='same')\n",
    "    x = tf.keras.layers.TimeDistributed(conv_2d_layer)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "\n",
    "    x = x * mask    \n",
    "    x = tf.math.reduce_sum(x, axis = [3,4])\n",
    "    mask_sum = tf.math.reduce_sum(mask, axis = [3,4])\n",
    "    x = (x / mask_sum)\n",
    "    \n",
    "    gru = tf.keras.layers.GRU(64, return_sequences=False, return_state=False)\n",
    "    x = gru(x)\n",
    "    \n",
    "    \n",
    "    y = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)(extra)\n",
    "    \n",
    "    x = tf.keras.layers.concatenate([x, y])\n",
    "    \n",
    "    \n",
    "    x = Dense(128, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(128, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(64, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(32, kernel_initializer = 'HeUniform')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(10, kernel_initializer = 'HeUniform')(x)\n",
    "    \n",
    "    \n",
    "    # construct the CNN\n",
    "    model = DropMaskModel(inputs=[img, mask, extra], outputs=x)\n",
    "    # return the CNN\n",
    "\n",
    "    return model\n",
    "\n",
    "cnn = create_cnn_GRU_norm(8, 32, 32, 15)\n",
    "#cnn.compile(optimizer = 'adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93df3ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "#tiles_test_dataset = tf.data.Dataset.list_files(f'/home/jupyter/NF-Capstone-Crop-Classification/stacked_files_CNN_test/*', shuffle=False)\n",
    "\n",
    "#fields_test_mean_var = pd.read_csv('data/mean_var_8days_test.csv')[['field_id', 'elevation', 'field_area_km2', 'sun_rate','neighboor_label_1', 'neighboor_label_2','neighboor_label_3',\n",
    "                                #'neighboor_label_4','neighboor_label_5', 'neighboor_label_6','neighboor_label_7', 'neighboor_label_8', 'neighboor_label_9']]\n",
    "\n",
    "#tiles_test = tilu.read_tile_geojson('data/tiles_train.geojson')\n",
    "#tiles_test_crs32634 = tiles_test.to_crs(32634)\n",
    "\n",
    "# apply with a threshold of 4000m\n",
    "#tiles_test['tiles_closest'] = tiles_test_crs32634.apply(tilu.tiles_closest, axis='columns', args=(tiles_train_crs32634, 4000,))\n",
    "\n",
    "for i, f in enumerate(tiles_test_dataset.as_numpy_iterator()):\n",
    "    if i == 0:\n",
    "        (test_ds, field_ids) = tile_dataset(f, train=False, radius=16, extra_data=fields_test_mean_var, tiles_info=tiles_test)\n",
    "    else:\n",
    "        (test_ds_append, field_ids_append) = tile_dataset(f, train=False, radius=16, extra_data=fields_test_mean_var, tiles_info=tiles_test)\n",
    "        test_ds = test_ds.concatenate(test_ds_append)\n",
    "        field_ids.extend(field_ids_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09ae0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "test_ds = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abdb0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape = (8, 15, 32, 32)\n",
    "img = tf.keras.Input(shape=inputShape, name='Input_Layer')\n",
    "mask = tf.keras.Input(shape=(1,1,32,32))\n",
    "extra = tf.keras.Input(shape=(13))\n",
    "\n",
    "x = cnn([img, mask, extra], training=False)\n",
    "x = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "prob_model = DropMaskModel(inputs=[img, mask, extra], outputs=x)\n",
    "\n",
    "\n",
    "prob_model.compile(optimizer = 'adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd940f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 38s 1s/step - loss: 0.8350 - accuracy: 0.7034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8349533081054688, 0.7033804655075073]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(val_ds, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e09b13c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 81s 2s/step\n"
     ]
    }
   ],
   "source": [
    "ds_test_pred_proba = prob_model.predict(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5db3015b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35295, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test_pred_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0754a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Build Submission\n",
    "df_field_ids = pd.DataFrame(field_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d27d6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol_proba = pd.DataFrame(((ds_test_pred_proba + 0.01)/np.sum((ds_test_pred_proba + 0.01), axis=1, keepdims=True)).round(2))\n",
    "#df_sol_proba = pd.DataFrame(ds_test_pred_proba.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4eff0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol = pd.concat([df_field_ids,df_sol_proba], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40e65ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2277</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7476</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35290</th>\n",
       "      <td>115450</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35291</th>\n",
       "      <td>116014</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35292</th>\n",
       "      <td>120968</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35293</th>\n",
       "      <td>122334</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35294</th>\n",
       "      <td>68605</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35295 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       field_id     0     1     2     3     4     5     6     7     8     9\n",
       "0          2199  0.00  0.00  0.00  0.01  0.98  0.00  0.00  0.00  0.00  0.00\n",
       "1          2277  0.00  0.04  0.08  0.08  0.74  0.04  0.01  0.01  0.00  0.00\n",
       "2          2571  0.00  0.06  0.17  0.09  0.59  0.05  0.01  0.01  0.00  0.00\n",
       "3          3112  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00\n",
       "4          7476  0.00  0.04  0.10  0.09  0.72  0.03  0.01  0.01  0.00  0.00\n",
       "...         ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
       "35290    115450  0.01  0.12  0.36  0.07  0.06  0.07  0.16  0.09  0.05  0.01\n",
       "35291    116014  0.00  0.25  0.38  0.07  0.06  0.07  0.09  0.04  0.02  0.02\n",
       "35292    120968  0.00  0.06  0.09  0.03  0.02  0.03  0.28  0.44  0.05  0.01\n",
       "35293    122334  0.00  0.14  0.55  0.08  0.10  0.07  0.03  0.02  0.01  0.01\n",
       "35294     68605  0.00  0.01  0.01  0.23  0.00  0.11  0.02  0.00  0.00  0.61\n",
       "\n",
       "[35295 rows x 11 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sol.columns = ['field_id',0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "df_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d745f899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field ID</th>\n",
       "      <th>Crop_Canola</th>\n",
       "      <th>Crop_Fallow</th>\n",
       "      <th>Crop_Lucerne/Medics</th>\n",
       "      <th>Crop_Planted pastures (perennial)</th>\n",
       "      <th>Crop_Rooibos</th>\n",
       "      <th>Crop_Small grain grazing</th>\n",
       "      <th>Crop_Weeds</th>\n",
       "      <th>Crop_Wheat</th>\n",
       "      <th>Crop_Wine grapes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2277</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7476</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35290</th>\n",
       "      <td>115450</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35291</th>\n",
       "      <td>116014</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35292</th>\n",
       "      <td>120968</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35293</th>\n",
       "      <td>122334</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35294</th>\n",
       "      <td>68605</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35295 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Field ID  Crop_Canola  Crop_Fallow  Crop_Lucerne/Medics  \\\n",
       "0          2199         0.00         0.01                 0.00   \n",
       "1          2277         0.00         0.08                 0.04   \n",
       "2          2571         0.00         0.09                 0.06   \n",
       "3          3112         0.00         0.00                 0.00   \n",
       "4          7476         0.00         0.09                 0.04   \n",
       "...         ...          ...          ...                  ...   \n",
       "35290    115450         0.05         0.07                 0.12   \n",
       "35291    116014         0.02         0.07                 0.25   \n",
       "35292    120968         0.05         0.03                 0.06   \n",
       "35293    122334         0.01         0.08                 0.14   \n",
       "35294     68605         0.00         0.23                 0.01   \n",
       "\n",
       "       Crop_Planted pastures (perennial)  Crop_Rooibos  \\\n",
       "0                                   0.00          0.00   \n",
       "1                                   0.08          0.00   \n",
       "2                                   0.17          0.00   \n",
       "3                                   0.00          0.00   \n",
       "4                                   0.10          0.00   \n",
       "...                                  ...           ...   \n",
       "35290                               0.36          0.01   \n",
       "35291                               0.38          0.02   \n",
       "35292                               0.09          0.01   \n",
       "35293                               0.55          0.01   \n",
       "35294                               0.01          0.61   \n",
       "\n",
       "       Crop_Small grain grazing  Crop_Weeds  Crop_Wheat  Crop_Wine grapes  \n",
       "0                          0.00        0.00        0.00              0.98  \n",
       "1                          0.01        0.04        0.01              0.74  \n",
       "2                          0.01        0.05        0.01              0.59  \n",
       "3                          0.00        0.00        0.00              1.00  \n",
       "4                          0.01        0.03        0.01              0.72  \n",
       "...                         ...         ...         ...               ...  \n",
       "35290                      0.16        0.07        0.09              0.06  \n",
       "35291                      0.09        0.07        0.04              0.06  \n",
       "35292                      0.28        0.03        0.44              0.02  \n",
       "35293                      0.03        0.07        0.02              0.10  \n",
       "35294                      0.02        0.11        0.00              0.00  \n",
       "\n",
       "[35295 rows x 10 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sol = df_sol[[\"field_id\", 8, 3, 1,2,9,6,5,7,4]]\n",
    "column_names = {\"field_id\": \"Field ID\",8:\"Crop_Canola\",3:\"Crop_Fallow\",1:\"Crop_Lucerne/Medics\",2:\"Crop_Planted pastures (perennial)\",9:\"Crop_Rooibos\",6:\"Crop_Small grain grazing\",5:\"Crop_Weeds\",7:\"Crop_Wheat\",4:\"Crop_Wine grapes\"}\n",
    "\n",
    "df_sol_clean = df_sol.rename(columns = column_names)\n",
    "df_sol_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0bd0f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol_clean.to_csv(\"Submission_LSTM-10Epochs.csv\", index=False, float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "aa808842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35295 entries, 0 to 35294\n",
      "Data columns (total 10 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Field ID                           35295 non-null  int32  \n",
      " 1   Crop_Canola                        35295 non-null  float32\n",
      " 2   Crop_Fallow                        35295 non-null  float32\n",
      " 3   Crop_Lucerne/Medics                35295 non-null  float32\n",
      " 4   Crop_Planted pastures (perennial)  35295 non-null  float32\n",
      " 5   Crop_Rooibos                       35295 non-null  float32\n",
      " 6   Crop_Small grain grazing           35295 non-null  float32\n",
      " 7   Crop_Weeds                         35295 non-null  float32\n",
      " 8   Crop_Wheat                         35295 non-null  float32\n",
      " 9   Crop_Wine grapes                   35295 non-null  float32\n",
      "dtypes: float32(9), int32(1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_sol_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82564763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
